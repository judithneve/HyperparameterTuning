---
title: "Data Generation"
author: "Judith Neve"
date: '2022-10-31'
output: html_document
---

# Works as should

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(pmsampsize)
library(tidyr)
library(MASS)
library(dplyr)
library(pROC)
```

```{r}
n_pred         <- c(8, 16, 32)
event_fraction <- c(0.1, 0.3, 0.5)
sample_size    <- c(0.5, 1, 2)
```

## Beta generation - trial 1

AUC: 0.7
1. Intercept + slope
2. Interaction

Note: gamma similar size, but vary between + and - so average 0

```{r}
source("GenerateBetas.R")
```

```{r}
start_seed <- 100
example_n <- 1e5
n_beta_repetitions <- 20

betas_matrix <- mean_multiple_betas(
  n_predictors = n_pred, prevalences = event_fraction, n_beta_repetitions = n_beta_repetitions,
  example_n = example_n, start_seed = start_seed
)
set.seed(2 * start_seed)
validation_betas_matrix <- validate_betas(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
set.seed(3 * start_seed)
validation_betas_matrix_noint <- validate_betas_noint(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)

save(betas_matrix, file = "betas.RData")
save(validation_betas_matrix, file = "valid.RData")
save(validation_betas_matrix_noint, file = "validnoint.RData")
```

```{r}
source("DataSimFunctions.R")
```

```{r}
scenarios <- make_scenarios(n_pred, event_fraction, sample_size)
dat <- sim_data(scenarios, betas_matrix, 1) # 1000 reps: 7GB - if stored as a list, 4GB
```

### Testing GLM

```{r}
toy_dat <- dat[dat[,"dataset_id"] == "19_1",] %>%
  as.data.frame() %>% 
  pivot_wider(names_from = Pred_number, values_from = Pred_value)

toy_dat[c(1, 7:14)]  <- lapply(toy_dat[c(1, 7:14)], as.numeric)

toy_dat$Y %>% mean()
```

```{r}
mod <- glm(Y ~ .*., data = toy_dat %>% select(-c(id, sample_size_prop, n_pred, event_fraction, dataset_id)), family = binomial())
# AUC and event faction also work?
summary(mod)
```

## Beta generation - trial 2

AUC: 0.7
1. Intercept + slope
2. Interaction

Note: gamma similar size, but vary between + and - so average 0

```{r}
source("GenerateBetas_1step.R")
```

```{r}
start_seed <- 100
example_n <- 1e4
n_beta_repetitions <- 5

betas_matrix <- mean_multiple_betas(
  n_predictors = n_pred, prevalences = event_fraction, n_beta_repetitions = n_beta_repetitions,
  example_n = example_n, start_seed = start_seed
)
set.seed(2 * start_seed)
validation_betas_matrix <- validate_betas(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
set.seed(3 * start_seed)
validation_betas_matrix_noint <- validate_betas_noint(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
```

```{r}
dat <- sim_data(scenarios, betas_matrix, 1) # 1000 reps: 7GB - if stored as a list, 4GB
```

### Testing GLM

```{r}
toy_dat <- dat[dat[,"dataset_id"] == "19_1",] %>%
  as.data.frame() %>% 
  pivot_wider(names_from = Pred_number, values_from = Pred_value)

toy_dat[c(1, 7:14)]  <- lapply(toy_dat[c(1, 7:14)], as.numeric)

toy_dat$Y %>% mean()
```

```{r}
mod <- glm(Y ~ .*., data = toy_dat %>% select(-c(id, sample_size_prop, n_pred, event_fraction, dataset_id)), family = binomial())
# AUC and event faction also work?
summary(mod)
```


## Beta generation - trial 3

AUC: 0.7
1. Intercept + slope
2. Interaction

Note: gamma similar size, but vary between + and - so average 0

```{r}
source("GenerateBetas_intgamma.R")
```

```{r}
start_seed <- 100
example_n <- 1e4
n_beta_repetitions <- 5

betas_matrix <- mean_multiple_betas(
  n_predictors = n_pred, prevalences = event_fraction, n_beta_repetitions = n_beta_repetitions,
  example_n = example_n, start_seed = start_seed
)
set.seed(2 * start_seed)
validation_betas_matrix <- validate_betas(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
set.seed(3 * start_seed)
validation_betas_matrix_noint <- validate_betas_noint(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
```

```{r}
dat <- sim_data(scenarios, betas_matrix, 1) # 1000 reps: 7GB - if stored as a list, 4GB
```

### Testing GLM

```{r}
toy_dat <- dat[dat[,"dataset_id"] == "19_1",] %>%
  as.data.frame() %>% 
  pivot_wider(names_from = Pred_number, values_from = Pred_value)

toy_dat[c(1, 7:14)]  <- lapply(toy_dat[c(1, 7:14)], as.numeric)

toy_dat$Y %>% mean()
```

```{r}
mod <- glm(Y ~ .*., data = toy_dat %>% select(-c(id, sample_size_prop, n_pred, event_fraction, dataset_id)), family = binomial())
# AUC and event faction also work?
summary(mod)
```


## Beta generation - trial 4

AUC: 0.7
1. Intercept + slope
2. Interaction

Note: gamma similar size, but vary between + and - so average 0

```{r}
source("GenerateBetas_3step.R")
```

```{r}
start_seed <- 100
example_n <- 1e4
n_beta_repetitions <- 20

betas_matrix <- mean_multiple_betas(
  n_predictors = n_pred, prevalences = event_fraction, n_beta_repetitions = n_beta_repetitions,
  example_n = example_n, start_seed = start_seed
)
set.seed(2 * start_seed)
validation_betas_matrix <- validate_betas(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
set.seed(3 * start_seed)
validation_betas_matrix_noint <- validate_betas_noint(
  betas_matrix = betas_matrix, example_n = example_n, n_predictors = n_pred, prevalences = event_fraction
)
```

```{r}
dat <- sim_data(scenarios, betas_matrix, 1) # 1000 reps: 7GB - if stored as a list, 4GB
```

### Testing GLM

```{r}
toy_dat <- dat[dat[,"dataset_id"] == "19_1",] %>%
  as.data.frame() %>% 
  pivot_wider(names_from = Pred_number, values_from = Pred_value)

toy_dat[c(1, 7:14)]  <- lapply(toy_dat[c(1, 7:14)], as.numeric)

toy_dat$Y %>% mean()
```

```{r}
mod <- glm(Y ~ .*., data = toy_dat %>% select(-c(id, sample_size_prop, n_pred, event_fraction, dataset_id)), family = binomial())
# AUC and event faction also work?
summary(mod)
```

# Tuning

```{r}
toy_dat <- dat[[i]][[j]]
```

```{r}
library(caret)
```

```{r}
# user friendly?? discussion point
# too many steps: how relevant? - side of what is usually done
set.seed(1)
# TODO: find how to make a full grid for ALL the hyperparameters I want
# TODO: have relevant values for the hyperparameters

defaults <- c(
  num.trees                 = 500,
  replace                   = TRUE,
  sample.fraction           = ifelse(replace, 1, 0.632),
  mtry                      = floor(sqrt(p)),
  respect.unordered.factors = "ignore", # but if splitrule = extratrees, this is "partition". "order" is also an option
  min.node.size             = 1,
  splitrule                 = "gini" # other options are extratrees and hellinger
  )


tuneGrid <- expand.grid(
  mtry = c(1:3),                                      # TODO: this goes to n_pred
  splitrule = c("gini", "extratrees", "hellinger"),
  min.node.size = c(1:5)                              # TODO: what's the biggest node size? n?
  )
ctrl <- trainControl(
  method = "cv",
  number = 5
)
# TODO: set the folds rather than have them be done within train

model1 <- train(
  x = toy_dat[,1:32],
  y = as.factor(toy_dat[,"Y"]),
  method = "ranger",
  trControl = ctrl,
  tuneGrid = tuneGrid,
  # hyperparameters not tuned by caret
  num.trees = 1,                        # change this to i and loop over doing this for many trees?
  replace = TRUE,                       # same code, replace = FALSE
  sample.fraction = 1,                  # same code, loop?
  respect.unordered.factors = "ignore"  # change this
)
model1
# TODO: how to extract results for best tune
```

