---
title: "Sneak peek at results"
author: "Judith Neve"
date: '2023-02-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Read in primary data

```{r}
# read all the files into a dataframe
df <- list.files(path = "./Data/sim/", pattern = ".rds") %>%
  paste0("./Data/sim/", .) %>% 
  map(readRDS) %>% 
  bind_rows()

df <- df %>% 
  # recode hyperparameter combination to say none
  mutate(hp_combination =
           ifelse(hp_combination == "",
                "None",
                hp_combination) %>%
           factor(),
         time = time*60) # convert runtime to seconds
```

# Primary data checks

```{r}
# check these are the updated data files: the oldest file should not be from before March 14th, 13:00
list.files(path = "./Data/sim/", pattern = ".rds") %>%
  paste0("./Data/sim/", .) %>% 
  file.info() %>% 
  pull(ctime) %>% 
  min()
```


```{r}
# check the number of unique datasets: we expect this to be 6000
unique(df$start_seed) %>% length()
# check which ones are missing
expected_seeds <- c((1:3000)*100 + 8, (1:3000)*100 + 16)
expected_seeds[!(expected_seeds %in% unique(df$start_seed))] %>% paste(collapse = ", ") # this is what we paste in "failed" to assess if these really would have needed longer to run
(expected_seeds[!(expected_seeds %in% unique(df$start_seed))]/100) %>% floor() %>% paste(collapse = ",") # this is what we paste into an sh file

failed <- c(6416, 7616, 8216, 10016, 19016, 22016, 22616, 23216, 23816, 24416, 25016, 25616, 26216, 26816, 27416, 28016, 28616, 29216, 29816,
            30416, 45416, 47816, 56216, 56816, 58616, 70616, 85616, 86816,
            5216, 9416, 13016, 16616, 20216, 30416, 45416, 47816, 56216, 56816, 58616, 70616, 85616, 86816,
            93416, 98216, 98816, 103016, 106016, 106616, 107216, 107816, 115016, 119216, 119816, 120416, 133016, 133616, 145616, 148016, 148616, 149216, 149816, 159416, 160616, 165416, 175016, 175616, 176816, 177416, 182216, 184616, 185216, 188216, 188816, 189416, 190016, 191216, 191816, 193016, 193616, 194216, 194816, 195416, 197216, 202616, 209216, 209816, 210416, 214616, 215816, 219416, 220016, 222416, 223016, 223616, 224816, 227216, 229616, 230216, 232016, 232616, 237416, 238016, 238616, 241016, 241616, 242216, 242816, 244616, 245216, 245816, 246416, 247016, 248216, 249416, 251216, 252416, 253016, 253616, 256616, 259016, 260816, 263816, 264416, 271016, 271616, 274616, 275816, 276416, 277616, 278816, 280616, 283016, 283616, 284816, 286616, 287816, 288416, 289616, 290816, 291416, 293216, 293816, 294416, 295616, 296216, 298616, 299216) %>%
  unique()
```


## Check time it took to rerun failed

```{r}
# in hours: is it more than 30:00:00 (the allotted runtime for this study)
df %>%
  filter(start_seed %in% failed) %>% 
  group_by(start_seed) %>% 
  summarise(time = sum(time)/3600) %>% 
  filter(time > 30)
```

# Plots

## Help dataframes

```{r scale setting}
# set the min and max value for the y-axis of each facet
df_scale_setter <- tibble(
  AUC = rep(c(0.5, 1), each = 9),
  BrierScore = rep(c(0, 1), each = 9),
  CalIntercept = rep(c(-1, 1), each = 9),
  CalSlope = rep(c(0, 5), each = 9),
  LogLoss = rep(c(0, 1), each = 9),
  Accuracy = rep(c(0, 1), each = 9),
  CohensKappa = rep(c(0, 1), each = 9),
  time = 0,
  hp_combination = rep(unique(df$hp_combination), 2)
) %>%
  pivot_longer(AUC:CohensKappa,
               names_to = "Metric",
               values_to = "Performance") %>%
  mutate(Metric = factor(Metric, levels = c("AUC", "CalSlope", "BrierScore", "CalIntercept", "LogLoss", "Accuracy", "CohensKappa")))

# information about what the "ideal" measure is
df_targets <- tibble(
  AUC = 1,
  BrierScore = 0,
  CalIntercept = 0,
  CalSlope = 1,
  LogLoss = 0,
  Accuracy = 1,
  CohensKappa = 1,
  time = 0,
  hp_combination = unique(df$hp_combination)
) %>%
  pivot_longer(AUC:CohensKappa,
               names_to = "Metric",
               values_to = "Target") %>%
  mutate(Metric = factor(Metric, levels = c("AUC", "CalSlope", "BrierScore", "CalIntercept", "LogLoss", "Accuracy", "CohensKappa")))

# set the limit for the x-axis: longest time for 8 predictors & longest time for 16 predictors (depending on the scenario)
df_timelimits <- expand.grid(
  hp_combination = unique(df$hp_combination),
  p              = c(8, 16),
  EF             = c(0.1, 0.3, 0.5),
  n_prop         = c(0.5, 1),
  Metric         = factor(c("AUC", "CalSlope", "BrierScore", "CalIntercept", "LogLoss", "Accuracy", "CohensKappa"), levels = c("AUC", "CalSlope", "BrierScore", "CalIntercept", "LogLoss", "Accuracy", "CohensKappa")),
  Performance    = 0
) %>% 
  mutate(time = ifelse(p == 8,
                       max(df %>% filter(p == 8) %>% pull(time)),
                       max(df %>% filter(p == 16) %>% pull(time))),
         scenario = paste(n_prop, p, EF)) %>% 
  arrange(p)

# labeller vectors
## performance metric
Metric.labs <- c("Calibration slope", "Calibration intercept", "Brier score", "Logarithmic loss", "AUC", "Classification accuracy", "Cohen's Kappa")
names(Metric.labs) <- c("CalSlope", "CalIntercept", "BrierScore", "LogLoss", "AUC", "Accuracy", "CohensKappa")
## hyperparameter combinations
HP.labs <- unique(df$hp_combination)
names(HP.labs) <- HP.labs
HP.labs <- c(HP.labs[which(HP.labs == "None")], sort(HP.labs[which(HP.labs != "None")]))[c(1,2,3,9,5,4,6,8,7)]
names(HP.labs)[9] <- "mtry + min.node.size\n+ sample.fraction + replace + splitrule"

# define the colour palette
HPcomb_pal <- viridis::turbo(n = 9)
```

## Report plots

```{r scenario by metric}
# full plot: facet by scenario and metric
plot_sc_met <- df %>%
  group_by(n_prop, p, EF) %>% 
  mutate(scenario = paste(n_prop, p, EF)) %>% 
  pivot_longer(AUC:CohensKappa,
               names_to = "Metric",
               values_to = "Performance") %>%
  mutate(Metric = factor(Metric,
                         levels = c("AUC", "CalSlope", "CalIntercept", "BrierScore", "LogLoss", "Accuracy", "CohensKappa"))) %>%
  ggplot(aes(x = time,
             y = Performance,
             group = hp_combination)) +
  geom_point(aes(col = hp_combination,
                 shape = hp_combination)) +
  geom_point(data = df_scale_setter, alpha = 0) +
  geom_point(data = df_timelimits, alpha = 0) +
  geom_hline(data = df_targets, aes(yintercept = Target), col = "red", lty = "dotted") +
  facet_wrap(factor(scenario, levels = unique(df_timelimits$scenario)) ~ Metric,
             scales = "free",
             labeller = labeller(Metric = Metric.labs),
             ncol = 7) +
  theme_classic() +
  theme(legend.text = element_text(size = 8),
        legend.key.size = unit(0.4, 'cm'),
        legend.background = element_rect(),
        panel.spacing = unit(1.2, "lines"),
        plot.caption = element_text(hjust = 0)) +
  scale_color_manual(breaks = HP.labs,
                     labels = names(HP.labs),
                     values = HPcomb_pal) +
  scale_shape_manual(breaks = HP.labs,
                     labels = names(HP.labs),
                     values = c(1, rep(16, 8))) +
  labs(x = "Runtime (seconds)",
       col = "Hyperparameter combination",
       shape = "Hyperparameter combination")
```

```{r}
# example plot: one scenario, facetted by performance metric
plot_ex_met <- df %>%
  filter(n_prop == 1,
         p      == 8,
         EF     == 0.3) %>% 
  pivot_longer(AUC:CohensKappa,
               names_to = "Metric",
               values_to = "Performance") %>%
  mutate(Metric = factor(Metric,
                         levels = c("AUC", "CalSlope", "CalIntercept", "BrierScore", "LogLoss", "Accuracy", "CohensKappa"))) %>%
  ggplot(aes(x = time,
             y = Performance,
             group = hp_combination)) +
  geom_point(aes(col = hp_combination,
                 shape = hp_combination)) +
  geom_point(data = df_scale_setter, alpha = 0) +
  geom_hline(data = df_targets, aes(yintercept = Target), col = "red", lty = "dotted") +
  facet_wrap(~ Metric,
             scales = "free",
             labeller = labeller(Metric = Metric.labs),
             ncol = 2) +
  theme_classic() +
  theme(#legend.position = c(.75, .1),
        legend.text = element_text(size = 8),
        legend.key.size = unit(0.4, 'cm'),
        legend.background = element_rect(),
        panel.spacing = unit(1.2, "lines"),
        plot.caption = element_text(hjust = 0)) +
  scale_color_manual(breaks = HP.labs,
                     labels = names(HP.labs),
                     values = HPcomb_pal) +
  scale_shape_manual(breaks = HP.labs,
                     labels = names(HP.labs),
                     values = c(1, rep(16, 8))) +
  labs(x = "Runtime (seconds)",
       col = "Hyperparameter combination",
       shape = "Hyperparameter combination")
```

# Summary statistics

```{r}
mean_AUC <- df$AUC %>% mean()
sd_AUC   <- df$AUC %>% sd()
```

```{r}
# primary outcome table
summary_table_study1 <- df %>%
  group_by(hp_combination) %>% 
  summarise(AUC_mean = round(mean(AUC), 2),
            AUC_sd = round(sd(AUC), 2),
            Calslope_median = round(median(CalSlope), 2),
            Calslope_IQR = round(IQR(CalSlope), 2),
            #Accuracy = paste0(round(mean(Accuracy),2), " (", round(sd(Accuracy), 2), ")"),
            `RMSD(slope)` = round(sqrt(mean((log(CalSlope))^2)), 2),
            Runtime_mean = round(mean(time), 1),
            Runtime_sd = round(sd(time), 1))
```

```{r}
# primary outcome table - per scenario
summary_table_study1_sc <- df %>%
  group_by(hp_combination, p, EF, n_prop) %>% 
  summarise(n = n(),
            AUC_mean = round(mean(AUC), 2),
            AUC_sd = round(sd(AUC), 2),
            Calslope_median = round(median(CalSlope), 2),
            Calslope_IQR = round(IQR(CalSlope), 2),
            #Accuracy = paste0(round(mean(Accuracy),2), " (", round(sd(Accuracy), 2), ")"),
            `RMSD(slope)` = round(sqrt(mean((log(CalSlope))^2)), 2),
            Runtime_mean = round(mean(time), 1),
            Runtime_sd = round(sd(time), 1))
```

# Per scenario tile plots

```{r}
# outcome plots
plot_calslope_s1 <- df %>%
  mutate(scenario = paste(n_prop, p, EF)) %>% 
  group_by(scenario, hp_combination) %>% 
  summarise(calslope = median(CalSlope)) %>% 
  ggplot(aes(x = scenario, y = hp_combination)) +
  geom_tile(aes(fill = calslope)) +  ##
  geom_text(aes(label = round(calslope, 2))) + ##
  scale_fill_gradient2(low = "white", high = "white", mid = "green", midpoint = 0, trans = "log")  + ## 
  xlab("Scenario") + 
  ylab("Hyperparameter combination") + 
  theme(panel.grid.major.x=element_blank(),
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(), 
        panel.background=element_rect(fill="white"))
plot_auc_s1 <- df %>%
  mutate(scenario = paste(n_prop, p, EF)) %>% 
  group_by(scenario, hp_combination) %>% 
  summarise(AUC = mean(AUC)) %>% 
  ggplot(aes(x = scenario, y = hp_combination)) +
  geom_tile(aes(fill = AUC)) +
  geom_text(aes(label = round(AUC, 2))) +
  scale_fill_gradient2(low = "white", high = "green")  +
  xlab("Scenario") + 
  ylab("Hyperparameter combination") + 
  theme(panel.grid.major.x=element_blank(),
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(), 
        panel.background=element_rect(fill="white"))
```

# Save the relevant plots and figures

```{r}
save(plot_ex_met, summary_table_study1, mean_AUC, sd_AUC, summary_table_study1_sc, plot_calslope_s1, plot_auc_s1, file = "Data/results.RData")
```


```{r}
df_casestudy <- df %>% 
  filter(p == 16,
         n_prop == 1,
         EF == 0.5,
         hp_combination == "mtry + min.node.size + sample.fraction + replace + splitrule") %>% 
  mutate(miscal = CalSlope > 2)

set.seed(100)
rerun <- ((df_casestudy %>% pull(start_seed) %>% sample(250)) - 16)/100
rerun[1:10] %>% paste(collapse = ",")

badcal <- ((df_casestudy %>% filter(miscal) %>% pull(start_seed)) - 16)/100
okcal  <- ((df_casestudy %>% filter(!miscal) %>% pull(start_seed)) - 16)/100

paste(c(badcal, okcal), collapse = ",")
```

```{r}
df_calsep <- list.files(path = "./Data/calsep/", pattern = ".rds") %>%
  paste0("./Data/calsep/", .) %>% 
  # file.info()
  map(readRDS) %>% 
  # mutate(splitrule = as.character(splitrule)) %>% 
  bind_rows()
```

```{r}
df <- df %>% 
  filter(start_seed %in% unique(df_calsep$start_seed))
```

```{r}
df_calsep %>% 
  filter(hp_combination %in% c("mtry + min.node.size + sample.fraction + replace + splitrule", "mtry + min.node.size + sample.fraction + splitrule", "mtry + min.node.size + splitrule", "mtry + min.node.size + replace + splitrule")) %>% 
  ggplot(aes(x = time, y = CalSlope, col = factor(splitrule))) +
  geom_point() +
  theme_classic() +
  facet_wrap(~ hp_combination, scales = "free")
```

