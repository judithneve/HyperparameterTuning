\begin{table}[p]
\centering
\caption{Data-generating scenarios}
\label{tab:scenarios}
\begin{tabular}{ccc}
  \hline
  $p$ & $EF$ & $n$ \\ \hline
  8 & 0.10 & 381 \\
   16 & 0.10 & 762 \\
    8 & 0.30 & 172 \\
   16 & 0.30 & 344 \\
    8 & 0.50 & 193 \\
   16 & 0.50 & 293 \\
    8 & 0.10 & 762 \\
   16 & 0.10 & 1523 \\
    8 & 0.30 & 344 \\
   16 & 0.30 & 688 \\
    8 & 0.50 & 385 \\
   16 & 0.50 & 585 \\
   \hline
\end{tabular}
\end{table}
\efloatseparator
 
\begin{table}[p]
\centering
\caption{Performance of selected true effects}
\label{tab:betastable}
\begin{tabular}{cccccccc}
  \hline
  $p$ & $EF$ (target) & $\beta_0$ & $\beta$ & $\gamma$ & AUC (no interaction) & AUC (interaction) & $EF$ (obtained) \\ \hline
8 & 0.10 & -2.98 & 0.14 & 0.66 & 0.71 & 0.80 & 0.10 \\
  8 & 0.30 & -0.94 & 0.24 & -0.84 & 0.70 & 0.80 & 0.30 \\
  8 & 0.50 & -0.22 & 0.22 & 0.83 & 0.70 & 0.80 & 0.50 \\
  16 & 0.10 & -3.06 & 0.07 & 0.44 & 0.70 & 0.80 & 0.10 \\
  16 & 0.30 & -0.85 & 0.14 & -0.55 & 0.70 & 0.80 & 0.30 \\
  16 & 0.50 & -0.31 & -0.13 & 0.55 & 0.70 & 0.80 & 0.50 \\
   \hline
\end{tabular}
\end{table}
\efloatseparator
 
\begin{table}[p]
    \centering
    \caption{Hyperparameter tuning ranges in studies 1 and 2}
    \begin{tabular}{ccc}
         \hline
         Hyperparameter & Default & Range\\
         \hline
         \texttt{mtry} & $\sqrt{p}$ (rounded down) & 1-$p$\\
         \texttt{min.node.size} & 1 & 1-10\\
         \hline
         \texttt{replace} & TRUE & TRUE, FALSE\\
         \texttt{sample.fraction} & 1 & 0.1, 0.2, ..., 0.9, 1\\
         \texttt{splitrule} & gini & gini, hellinger, extratrees*\\
         \hline
    \end{tabular}
    \begin{tablenotes}
      \item *For \texttt{splitrule} = \texttt{extratrees}, an additional parameter should be considered regarding the number of random splits to consider. This was set to its default of 1.
    \end{tablenotes}
    \label{tab:hyp_ranges}
\end{table}
\efloatseparator
 
\begin{table}[tb]
    \caption{Optimisation metric targets}
    \centering
    \begin{tabular}{cccc}
        \hline
        Metric & Target & Range of possible values\\
        \hline
        Deviance & 0 & [0, $\infty$]\\
        Logarithmic loss & 0 & [0, 1]\\
        AUC & 1 & [0.5, 1]\\
        Brier score & 0 & [0, 1]\\
        Calibration intercept* & 0 & [$-\infty$, $\infty$]\\
        Calibration slope** & 1 & [0, $\infty$]\\
        Classification accuracy & 1 & [0, 1]\\
        Cohen's Kappa & 1 & [0, 1]\\
        \hline
    \end{tabular}
    \begin{tablenotes}
      \item *optimised by minimising the squared value.
      \item **optimised by minimising the squared natural log of the value.
    \end{tablenotes}
    \label{tab:metrics}
\end{table}
\efloatseparator
 
\begin{table}[p]
\centering
\caption{Average performance of hyperparameter combinations (aggregated over all scenarios). Rows are sorted in ascending order of runtime.}
\label{tab:results1}
\scalebox{0.9}{
\begin{tabular}{lcccr}
  \hline
  \multicolumn{1}{c}{Tuned hyperparameters}& \multicolumn{1}{c}{AUC}& \multicolumn{1}{c}{Calibration slope}& \multicolumn{1}{c}{RMSD(slope)}& \multicolumn{1}{c}{Runtime (seconds)}\\\multicolumn{1}{c}{}& \multicolumn{1}{c}{Mean (SD)}& \multicolumn{1}{c}{Median (IQR)}& \multicolumn{1}{c}{}& \multicolumn{1}{c}{Mean (SD)}\\ \hline
None & 0.70 (0.02) & 0.89 (0.27) & 0.23 &     1.80 (00001.40) \\
  mtry + min.node.size & 0.70 (0.02) & 1.05 (0.27) & 0.21 &   278.20 (00312.40) \\
  mtry + min.node.size + replace & 0.70 (0.02) & 1.03 (0.27) & 0.21 &   639.00 (00726.70) \\
  mtry + min.node.size + splitrule & 0.71 (0.02) & 1.16 (0.34) & 0.28 &   782.50 (00782.50) \\
  mtry + min.node.size + sample.fraction & 0.70 (0.02) & 1.09 (0.29) & 0.23 &  1776.10 (01879.40) \\
  mtry + min.node.size + replace + splitrule & 0.71 (0.02) & 1.13 (0.34) & 0.27 &  1829.60 (01856.30) \\
  mtry + min.node.size + sample.fraction + replace & 0.70 (0.02) & 1.07 (0.29) & 0.24 &  3918.80 (04206.90) \\
  mtry + min.node.size + sample.fraction + splitrule & 0.71 (0.02) & 1.16 (0.33) & 0.27 &  5023.00 (04758.20) \\
  mtry + min.node.size + sample.fraction + replace + splitrule & 0.71 (0.02) & 1.13 (0.33) & 0.26 & 11185.40 (10750.00) \\
   \hline
\end{tabular}
}
\end{table}
\efloatseparator
 
\begin{table}[p]
\centering
\caption{Average performance of optimisation metrics (aggregated over all scenarios). Rows are sorted in ascending order of RMSD(slope).}
\label{tab:results2}
\begin{tabular}{lcccc}
  \hline
  \multicolumn{1}{c}{Optimisation metric}& \multicolumn{1}{c}{AUC}& \multicolumn{1}{c}{Calibration slope}& \multicolumn{1}{c}{RMSD(slope)}& \multicolumn{1}{c}{Runtime (seconds)}\\\multicolumn{1}{c}{}& \multicolumn{1}{c}{Mean (SD)}& \multicolumn{1}{c}{Median (IQR)}& \multicolumn{1}{c}{}& \multicolumn{1}{c}{Mean (SD)}\\ \hline
Logarithmic loss & 0.70 (0.02) & 1.05 (0.28) & 0.20 & 261.70 (301.40) \\
  Calibration slope & 0.70 (0.02) & 0.98 (0.27) & 0.21 & 263.00 (301.90) \\
  Deviance & 0.70 (0.02) & 1.05 (0.28) & 0.21 & 261.70 (301.40) \\
  Brier score & 0.70 (0.02) & 1.03 (0.29) & 0.22 & 261.40 (300.80) \\
  Calibration intercept & 0.70 (0.02) & 1.13 (0.31) & 0.23 & 262.90 (301.30) \\
  AUC & 0.70 (0.02) & 1.04 (0.33) & 0.27 & 262.20 (301.60) \\
  Classification accuracy & 0.70 (0.02) & 0.90 (0.33) & 0.30 & 262.00 (301.50) \\
  Cohen's Kappa & 0.70 (0.02) & 0.78 (0.36) & 0.42 & 262.10 (301.50) \\
   \hline
\end{tabular}
\end{table}
\efloatseparator
 
\begin{table}[p]
\centering
\caption{Average performance of hyperparameter search algorithms (aggregated over all scenarios). Rows are sorted in ascending order of runtime.}
\label{tab:results3}
\begin{tabular}{lcccr}
  \hline
  \multicolumn{1}{c}{Search algorithm}& \multicolumn{1}{c}{AUC}& \multicolumn{1}{c}{Calibration slope}& \multicolumn{1}{c}{RMSD(slope)}& \multicolumn{1}{c}{Runtime (seconds)}\\\multicolumn{1}{c}{}& \multicolumn{1}{c}{Mean (SD)}& \multicolumn{1}{c}{Median (IQR)}& \multicolumn{1}{c}{}& \multicolumn{1}{c}{Mean (SD)}\\ \hline
Model-based optimisation & 0.70 (0.02) & 1.07 (0.28) & 0.21 &  70.50 (032.10) \\
  Random search & 0.70 (0.02) & 1.06 (0.29) & 0.22 &  97.40 (127.70) \\
  Grid search & 0.70 (0.02) & 1.05 (0.28) & 0.21 & 268.30 (305.80) \\
   \hline
\end{tabular}
\end{table}
